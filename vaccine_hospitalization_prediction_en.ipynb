{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94becae9-3511-43fa-8071-194b0457cec2",
   "metadata": {},
   "source": [
    "# Building and Comparing Machine Learning Models to Predict Hospitalization and Length of Stay After Vaccination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e7da3bb-b695-40c2-9137-9314ffafd851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\okada\\anaconda3\\envs\\fraud-detect\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "# Basic Libraries\n",
    "# ---------------------------------------\n",
    "import os                              # File operations\n",
    "import zipfile                         # Handling zip files\n",
    "import numpy as np                     # Numerical operations\n",
    "import pandas as pd                    # DataFrame operations\n",
    "import matplotlib.pyplot as plt        # Plotting\n",
    "import shap                            # SHAP visualization\n",
    "\n",
    "# ---------------------------------------\n",
    "# Preprocessing / Data Splitting\n",
    "# ---------------------------------------\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV   # Train-test split, Grid search\n",
    "from sklearn.preprocessing import LabelEncoder                       # Label encoding\n",
    "from sklearn.preprocessing import OneHotEncoder                      # One-hot encoding\n",
    "from sklearn.compose import ColumnTransformer                        # Apply preprocessing per column\n",
    "from sklearn.pipeline import Pipeline                                # Combine preprocessing and model steps\n",
    "from sklearn.impute import SimpleImputer                             # Missing value imputation\n",
    "\n",
    "# ---------------------------------------\n",
    "# Models\n",
    "# ---------------------------------------\n",
    "from sklearn.linear_model import LinearRegression        # Linear regression\n",
    "from sklearn.ensemble import RandomForestClassifier      # Random forest\n",
    "from lightgbm import LGBMClassifier                      # LightGBM (model)\n",
    "import lightgbm as lgb                                   # LightGBM (for SHAP, etc.)\n",
    "\n",
    "# ---------------------------------------\n",
    "# Model Evaluation\n",
    "# ---------------------------------------\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    classification_report, confusion_matrix,\n",
    "    mean_absolute_error, mean_squared_error, r2_score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dbd60c-88b1-4aef-859f-49c0e73c56ef",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c475355-efd2-4c1e-b430-7e02bf0b4944",
   "metadata": {},
   "source": [
    "### 1.1 Objective and Background\n",
    "In this project, we use post-vaccination patient data to build a regression model that predicts the number of hospitalization days (HOSPDAYS), as well as a classification model that predicts whether hospitalization occurred (HOSPITAL).\n",
    "The goal is to utilize this data to support resource allocation and decision-making in medical institutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db72f5d9-f14c-4db7-a2ea-7d5dc611096b",
   "metadata": {},
   "source": [
    "### 1.2 Data Used\n",
    "For this analysis, we used data from the VAERS (Vaccine Adverse Event Reporting System), collected in the United States in 2020.\n",
    "This publicly available dataset contains records of adverse events following vaccination and includes various information such as age, sex, vaccine type, date of onset, symptoms, and medical history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f02426c-bced-44a5-a887-f5e68491d280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>カラム名</th>\n",
       "      <th>データ型</th>\n",
       "      <th>説明</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGE_YRS</td>\n",
       "      <td>Num (xxx.x)</td>\n",
       "      <td>年齢（単位：歳）</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAGE_YR</td>\n",
       "      <td>Num (xxx)</td>\n",
       "      <td>年齢（年単位、計算値）</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAGE_MO</td>\n",
       "      <td>Num (x.x)</td>\n",
       "      <td>年齢（月単位、計算値）</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SEX</td>\n",
       "      <td>Char (1)</td>\n",
       "      <td>性別（M/F/U）</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOSPDAYS</td>\n",
       "      <td>Num (3)</td>\n",
       "      <td>入院日数</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VAX_DATE</td>\n",
       "      <td>Date</td>\n",
       "      <td>ワクチン接種日</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ONSET_DATE</td>\n",
       "      <td>Date</td>\n",
       "      <td>有害事象の発生日</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NUMDAYS</td>\n",
       "      <td>Num (5)</td>\n",
       "      <td>潜伏期間（日数）</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>V_ADMINBY</td>\n",
       "      <td>Char (3)</td>\n",
       "      <td>ワクチン接種を実施した施設の種類</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CUR_ILL</td>\n",
       "      <td>Char (32000)</td>\n",
       "      <td>接種時の既往症や疾患</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HISTORY</td>\n",
       "      <td>Char (32000)</td>\n",
       "      <td>長期的・慢性的な健康状態</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PRIOR_VAX</td>\n",
       "      <td>Char (128)</td>\n",
       "      <td>過去のワクチン接種歴</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BIRTH_DEFECT</td>\n",
       "      <td>Char (1)</td>\n",
       "      <td>先天性異常または先天性欠損</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>OFC_VISIT</td>\n",
       "      <td>Char (1)</td>\n",
       "      <td>医師またはその他の医療提供者の診療所・クリニックへの受診</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ER_ED_VISIT</td>\n",
       "      <td>Char (1)</td>\n",
       "      <td>緊急処置室などの受診有無</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ALLERGIES</td>\n",
       "      <td>Char (32000)</td>\n",
       "      <td>薬、食べ物、またはその他の製品に対するアレルギー</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            カラム名          データ型                            説明\n",
       "0        AGE_YRS   Num (xxx.x)                      年齢（単位：歳）\n",
       "1        CAGE_YR     Num (xxx)                   年齢（年単位、計算値）\n",
       "2        CAGE_MO     Num (x.x)                   年齢（月単位、計算値）\n",
       "3            SEX      Char (1)                     性別（M/F/U）\n",
       "4       HOSPDAYS       Num (3)                          入院日数\n",
       "5       VAX_DATE          Date                       ワクチン接種日\n",
       "6     ONSET_DATE          Date                      有害事象の発生日\n",
       "7        NUMDAYS       Num (5)                      潜伏期間（日数）\n",
       "8      V_ADMINBY      Char (3)              ワクチン接種を実施した施設の種類\n",
       "9        CUR_ILL  Char (32000)                    接種時の既往症や疾患\n",
       "10       HISTORY  Char (32000)                  長期的・慢性的な健康状態\n",
       "11     PRIOR_VAX    Char (128)                    過去のワクチン接種歴\n",
       "12  BIRTH_DEFECT      Char (1)                 先天性異常または先天性欠損\n",
       "13     OFC_VISIT      Char (1)  医師またはその他の医療提供者の診療所・クリニックへの受診\n",
       "14   ER_ED_VISIT      Char (1)                  緊急処置室などの受診有無\n",
       "15     ALLERGIES  Char (32000)      薬、食べ物、またはその他の製品に対するアレルギー"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV file\n",
    "df_data = pd.read_csv(r'C:\\Users\\okada\\VAERS_Columns.csv')\n",
    "\n",
    "# Display the contents of the data\n",
    "df_data.head(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7b640f-701a-4a7d-9035-0aafa8fdcb9a",
   "metadata": {},
   "source": [
    "## 2. Regression Model for Predicting Hospitalization Days\n",
    "In this analysis, we first applied a simple linear regression model, and then used LightGBM, which can capture nonlinear relationships, in order to improve the prediction accuracy of hospitalization days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9926ac88-b406-4c8c-aa68-2e6dcf5c7da1",
   "metadata": {},
   "source": [
    "### 2.1 Data Inspection and Preprocessing\n",
    "Before building the model, we performed preprocessing tasks such as missing value imputation, outlier removal, feature engineering, and encoding of categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ca743c9-dc6b-4fed-b031-b50118b85f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAERS_ID</th>\n",
       "      <th>RECVDATE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>AGE_YRS</th>\n",
       "      <th>CAGE_YR</th>\n",
       "      <th>CAGE_MO</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RPT_DATE</th>\n",
       "      <th>SYMPTOM_TEXT</th>\n",
       "      <th>DIED</th>\n",
       "      <th>...</th>\n",
       "      <th>CUR_ILL</th>\n",
       "      <th>HISTORY</th>\n",
       "      <th>PRIOR_VAX</th>\n",
       "      <th>SPLTTYPE</th>\n",
       "      <th>FORM_VERS</th>\n",
       "      <th>TODAYS_DATE</th>\n",
       "      <th>BIRTH_DEFECT</th>\n",
       "      <th>OFC_VISIT</th>\n",
       "      <th>ER_ED_VISIT</th>\n",
       "      <th>ALLERGIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>902418</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>NJ</td>\n",
       "      <td>56.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Patient experienced mild numbness traveling fr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>902440</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>AZ</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C/O Headache</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>902446</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>WV</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>felt warm, hot and face and ears were red and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>Hypertension, sleep apnea, hypothyroidism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contrast Dye IV contrast, shellfish, strawberry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>902464</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>LA</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>within 15 minutes progressive light-headedness...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>902465</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>AR</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pt felt wave come over body @ 1218 starting in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Bronchitis, finished prednisone on 12-13-20</td>\n",
       "      <td>hypertension, fibromyalgia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12/15/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Biaxin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VAERS_ID    RECVDATE STATE  AGE_YRS  CAGE_YR  CAGE_MO SEX RPT_DATE  \\\n",
       "0    902418  12/15/2020    NJ     56.0     56.0      NaN   F      NaN   \n",
       "1    902440  12/15/2020    AZ     35.0     35.0      NaN   F      NaN   \n",
       "2    902446  12/15/2020    WV     55.0     55.0      NaN   F      NaN   \n",
       "3    902464  12/15/2020    LA     42.0     42.0      NaN   M      NaN   \n",
       "4    902465  12/15/2020    AR     60.0     60.0      NaN   F      NaN   \n",
       "\n",
       "                                        SYMPTOM_TEXT DIED  ...  \\\n",
       "0  Patient experienced mild numbness traveling fr...  NaN  ...   \n",
       "1                                       C/O Headache  NaN  ...   \n",
       "2  felt warm, hot and face and ears were red and ...  NaN  ...   \n",
       "3  within 15 minutes progressive light-headedness...  NaN  ...   \n",
       "4  Pt felt wave come over body @ 1218 starting in...  NaN  ...   \n",
       "\n",
       "                                       CUR_ILL  \\\n",
       "0                                         none   \n",
       "1                                          NaN   \n",
       "2                                         none   \n",
       "3                                         none   \n",
       "4  Bronchitis, finished prednisone on 12-13-20   \n",
       "\n",
       "                                     HISTORY PRIOR_VAX SPLTTYPE  FORM_VERS  \\\n",
       "0                                       none       NaN      NaN        2.0   \n",
       "1                                        NaN       NaN      NaN        2.0   \n",
       "2  Hypertension, sleep apnea, hypothyroidism       NaN      NaN        2.0   \n",
       "3                                       none       NaN      NaN        2.0   \n",
       "4                 hypertension, fibromyalgia       NaN      NaN        2.0   \n",
       "\n",
       "  TODAYS_DATE BIRTH_DEFECT OFC_VISIT ER_ED_VISIT  \\\n",
       "0  12/15/2020          NaN       NaN         NaN   \n",
       "1  12/15/2020          NaN       NaN         NaN   \n",
       "2  12/15/2020          NaN       NaN         NaN   \n",
       "3  12/15/2020          NaN       NaN           Y   \n",
       "4  12/15/2020          NaN       NaN         NaN   \n",
       "\n",
       "                                         ALLERGIES  \n",
       "0                                             none  \n",
       "1                                              NaN  \n",
       "2  Contrast Dye IV contrast, shellfish, strawberry  \n",
       "3                                             none  \n",
       "4                                           Biaxin  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==========================\n",
    "# ZIP File Extraction Process\n",
    "# ==========================\n",
    "\n",
    "# Set path to the extracted CSV file\n",
    "zip_path = 'VAERSDATA.csv.zip'\n",
    "extract_dir = 'unzipped_drug_data'\n",
    "\n",
    "# Unzip the file\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "\n",
    "# Set path to the extracted CSV file\n",
    "csv_file_path = os.path.join(extract_dir, 'VAERSDATA.csv')\n",
    "\n",
    "# Load the CSV file with low_memory=False\n",
    "df = pd.read_csv(csv_file_path, low_memory=False)\n",
    "\n",
    "# Preview the top rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eec9f6b-4a6e-48bc-878c-bae256b90ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of each column:\n",
      "VAERS_ID          int64\n",
      "RECVDATE         object\n",
      "STATE            object\n",
      "AGE_YRS         float64\n",
      "CAGE_YR         float64\n",
      "CAGE_MO         float64\n",
      "SEX              object\n",
      "RPT_DATE         object\n",
      "SYMPTOM_TEXT     object\n",
      "DIED             object\n",
      "DATEDIED         object\n",
      "L_THREAT         object\n",
      "ER_VISIT         object\n",
      "HOSPITAL         object\n",
      "HOSPDAYS        float64\n",
      "X_STAY           object\n",
      "DISABLE          object\n",
      "RECOVD           object\n",
      "VAX_DATE         object\n",
      "ONSET_DATE       object\n",
      "NUMDAYS         float64\n",
      "LAB_DATA         object\n",
      "V_ADMINBY        object\n",
      "V_FUNDBY         object\n",
      "OTHER_MEDS       object\n",
      "CUR_ILL          object\n",
      "HISTORY          object\n",
      "PRIOR_VAX        object\n",
      "SPLTTYPE         object\n",
      "FORM_VERS       float64\n",
      "TODAYS_DATE      object\n",
      "BIRTH_DEFECT     object\n",
      "OFC_VISIT        object\n",
      "ER_ED_VISIT      object\n",
      "ALLERGIES        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Check Data Types\n",
    "# ==========================\n",
    "\n",
    "# Check data types of each column\n",
    "print(\"Data types of each column:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7583cf57-a265-4cfc-8012-b11bd85a0893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Preprocessing\n",
    "# ========================\n",
    "\n",
    "# ------------------------\n",
    "# Convert to datetime format\n",
    "# ------------------------\n",
    "df['ONSET_DATE'] = pd.to_datetime(df['ONSET_DATE'], errors='coerce')\n",
    "df['VAX_DATE'] = pd.to_datetime(df['VAX_DATE'], errors='coerce')\n",
    "\n",
    "# ------------------------\n",
    "# Remove outliers \n",
    "# (Remove top 1% of HOSPDAYS and IQR outliers for NUMDAYS)\n",
    "# ------------------------\n",
    "def remove_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "threshold = df['HOSPDAYS'].quantile(0.99)\n",
    "df_filtered = df[df['HOSPDAYS'] <= threshold]\n",
    "df_filtered = remove_outliers_iqr(df_filtered, 'NUMDAYS')\n",
    "\n",
    "# ------------------------\n",
    "# Feature engineering\n",
    "# ------------------------\n",
    "df_reg = pd.DataFrame()\n",
    "\n",
    "# Numerical and conditional features\n",
    "df_reg['AGE_YRS'] = df['AGE_YRS']\n",
    "df_reg['NUMDAYS'] = df['NUMDAYS']\n",
    "\n",
    "# Binary features (flag presence/absence of information)\n",
    "df_reg['has_allergy'] = df['ALLERGIES'].notna().astype(int)\n",
    "df_reg['has_diabetes'] = df['HISTORY'].astype(str).str.contains('diabet', case=False, na=False).astype(int)\n",
    "df_reg['has_hypertension'] = df['HISTORY'].astype(str).str.contains('hyper', case=False, na=False).astype(int)\n",
    "df_reg['has_current_illness'] = df['CUR_ILL'].notna().astype(int)\n",
    "df_reg['has_prior_vax'] = df['PRIOR_VAX'].notna().astype(int)\n",
    "\n",
    "# Categorical variables (sex, vaccine administrator)\n",
    "df_reg['SEX'] = df['SEX']\n",
    "df_reg['V_ADMINBY'] = df['V_ADMINBY']\n",
    "\n",
    "# Time-based features (weekday and month)\n",
    "df_reg['ONSET_WEEKDAY'] = df['ONSET_DATE'].dt.weekday\n",
    "df_reg['ONSET_MONTH'] = df['ONSET_DATE'].dt.month\n",
    "\n",
    "# Extract rows to match the filtered dataset (df_filtered)\n",
    "df_reg = df_reg.loc[df_filtered.index]\n",
    "\n",
    "# ------------------------\n",
    "# Use OneHotEncoder for preprocessing\n",
    "# ------------------------\n",
    "X = df_reg\n",
    "y = df_filtered['HOSPDAYS']\n",
    "\n",
    "categorical_cols = ['SEX', 'V_ADMINBY']\n",
    "numeric_cols = X.drop(columns=categorical_cols).columns.tolist()\n",
    "\n",
    "# Define preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', SimpleImputer(strategy='mean'), numeric_cols),\n",
    "    ('cat', Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ]), categorical_cols)\n",
    "])\n",
    "\n",
    "# Apply preprocessing\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Retrieve column names\n",
    "cat_ohe = preprocessor.named_transformers_['cat'].named_steps['ohe']\n",
    "cat_ohe_cols = cat_ohe.get_feature_names_out(categorical_cols)\n",
    "final_columns = numeric_cols + cat_ohe_cols.tolist()\n",
    "\n",
    "# Convert to DataFrame\n",
    "X_imputed = pd.DataFrame(X_processed, columns=final_columns, index=X.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b72b0c-f726-4ba3-b930-c7b9610da57e",
   "metadata": {},
   "source": [
    "### 2.2 Linear Regression Model\n",
    "As a basic approach, we built a simple linear regression model to examine the linear relationship between the number of hospitalization days and various features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2a0b400-0d5f-4998-821a-635d8fc840e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Model training and evaluation (Linear Regression)\n",
    "# ========================\n",
    "\n",
    "# Data splitting (training and test sets)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b553a42-9b43-4d2e-aa5f-862c060cc7b1",
   "metadata": {},
   "source": [
    "### 2.3 LightGBM\n",
    "Aiming for more accurate predictions, we introduced LightGBM, which is capable of capturing complex structures, to improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c2832f1-4d59-41b0-bccd-dd6bc5263e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 177\n",
      "[LightGBM] [Info] Number of data points in the train set: 9370, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 4.199680\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Model training and evaluation (LightGBM Regression)\n",
    "# ========================\n",
    "\n",
    "# Model training (LightGBM Regression)\n",
    "model = lgb.LGBMRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_lgb = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1ca26b-5695-45a9-acba-61a3d82853bf",
   "metadata": {},
   "source": [
    "### 2.4 Comparison and Evaluation of Models Predicting Hospitalization Days\n",
    "The constructed models were evaluated using prediction accuracy and error indicators such as MAE, RMSE, and R²."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18029b88-e86e-48d2-8ccb-9c8488706a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>2.719741</td>\n",
       "      <td>4.066231</td>\n",
       "      <td>0.010187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>2.699166</td>\n",
       "      <td>4.023093</td>\n",
       "      <td>0.031077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model       MAE      RMSE        R²\n",
       "0  RandomForest  2.719741  4.066231  0.010187\n",
       "1      LightGBM  2.699166  4.023093  0.031077"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ========================\n",
    "# Evaluation of Regression Models\n",
    "# ========================\n",
    "\n",
    "# Collecting evaluation indicators (MAE, RMSE, R²)\n",
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"RandomForest\", \"LightGBM\"],\n",
    "    \"MAE\": [mean_absolute_error(y_test, y_pred_lgb), mean_absolute_error(y_test, y_pred_rf)],\n",
    "    \"RMSE\": [np.sqrt(mean_squared_error(y_test, y_pred_lgb)), np.sqrt(mean_squared_error(y_test, y_pred_rf))],\n",
    "    \"R²\": [r2_score(y_test, y_pred_lgb), r2_score(y_test, y_pred_rf)],\n",
    "})\n",
    "\n",
    "# Display the results\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85374811-bdad-461d-84e6-9f5ddb9cac91",
   "metadata": {},
   "source": [
    "In this section, we compared the representative linear regression model for regression tasks with the non-linear model LightGBM. However, since both R² scores were below 0.05, the accuracy of the predictions for hospitalization days is insufficient. This could be due to the limited factors influencing hospitalization duration in the dataset or a skewed distribution in the number of hospitalization days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4565b0be-67ed-4183-a59d-c70d17aef156",
   "metadata": {},
   "source": [
    "## 3. Classification Model for Predicting Hospitalization (Yes/No)\n",
    "Following the regression analysis in the previous section, we built and evaluated classification models using Random Forest and LightGBM to predict whether hospitalization occurred (a binary classification task)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da2f232-b738-40d3-a9a6-90f938133765",
   "metadata": {},
   "source": [
    "### 3.1 Data Verification and Preprocessing\n",
    "In this section, we perform data verification and preprocessing for constructing a classification model that predicts hospitalization. This includes data checking, removal of unnecessary variables, missing value imputation, label creation, and class balancing via downsampling, as well as feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd09d0c7-01e5-4b4a-851e-19ff963cd29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Preprocessing for Classification Model\n",
    "# ============================\n",
    "\n",
    "# ----------------------------\n",
    "# Data Copy & Label Creation (Binary Classification of Hospitalization)\n",
    "# ----------------------------\n",
    "df_clf = df.copy()\n",
    "df_clf['HOSPDAYS_label'] = df_clf['HOSPDAYS'].notna().astype(int)\n",
    "\n",
    "# ----------------------------\n",
    "# Drop Columns That Might Leak Information\n",
    "# ----------------------------\n",
    "leak_cols = [\n",
    "    'DATE DIED', 'DISABLE', 'RECOVD', 'NUMDAYS', 'ER_VISIT', 'ER_VISIT_len', 'RECORD_len',\n",
    "    'HOSPITAL', 'VAERS_ID', 'RECVDATE', 'X_STAY', 'FORM_VERS', 'TODAYS_DATE',\n",
    "    'STATE', 'RPT_DATE', 'SYMPTOM_TEXT', 'DIED', 'DATEDIED', 'L_THREAT',\n",
    "    'VAX_DATE', 'SPLTTYPE', 'LAB_DATA', 'HISTORY', 'OTHER_MEDS', 'CUR_ILL', 'V_FUNDBY', 'ER_VISIT'\n",
    "]\n",
    "df_clf = df_clf.drop(columns=[col for col in leak_cols if col in df_clf.columns], errors='ignore')\n",
    "\n",
    "# ----------------------------\n",
    "# Balancing Classes Using Downsampling\n",
    "# ----------------------------\n",
    "df_pos = df_clf[df_clf['HOSPDAYS_label'] == 1]\n",
    "df_neg = df_clf[df_clf['HOSPDAYS_label'] == 0].sample(n=len(df_pos), random_state=42)\n",
    "df_balanced = pd.concat([df_pos, df_neg]).reset_index(drop=True)\n",
    "\n",
    "# ----------------------------\n",
    "# Splitting Features and Target Variables\n",
    "# ----------------------------\n",
    "X = df_balanced.drop(columns=['HOSPDAYS', 'HOSPDAYS_label'])\n",
    "y_class = df_balanced['HOSPDAYS_label']\n",
    "\n",
    "# ----------------------------\n",
    "# Feature Creation (Time-based, Vaccine History)\n",
    "# ----------------------------\n",
    "X['ONSET_LAG'] = (df['ONSET_DATE'] - df['VAX_DATE']).dt.days  # Incubation period (in days)\n",
    "X['ONSET_WEEKDAY'] = df['ONSET_DATE'].dt.weekday  # Day of onset (weekday)\n",
    "X['ONSET_MONTH'] = df['ONSET_DATE'].dt.month  # Month of onset\n",
    "X['has_prior_vax'] = df['PRIOR_VAX'].notna().astype(int)  # Presence of prior vaccination\n",
    "\n",
    "# ----------------------------\n",
    "# Filling Missing Age Information (Prefer AGE_YRS; if not, use CAGE_MO)\n",
    "# ----------------------------\n",
    "X['AGE_YRS'] = X['AGE_YRS'].fillna(X['CAGE_YR'])\n",
    "X['AGE_YRS'] = X['AGE_YRS'].fillna(X.get('CAGE_MO', 0) / 12)\n",
    "\n",
    "# Dropping Unnecessary Columns\n",
    "X = X.drop(columns=['CAGE_YR', 'CAGE_MO'], errors='ignore')\n",
    "\n",
    "# ----------------------------\n",
    "# Label Encoding for Categorical Variables\n",
    "# ----------------------------\n",
    "for col in X.select_dtypes(include='object').columns:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))  # Convert NaN to 'nan' and encode\n",
    "\n",
    "# ----------------------------\n",
    "# Dropping Datetime Columns (to Prevent Errors During Imputation)\n",
    "# ----------------------------\n",
    "X = X.drop(columns=X.select_dtypes(include='datetime64').columns, errors='ignore')\n",
    "\n",
    "# ----------------------------\n",
    "# Missing Value Imputation (Using the Most Frequent Value)\n",
    "# ----------------------------\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# ----------------------------\n",
    "# Train-Test Split\n",
    "# ----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_class, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134ae130-fb79-42a0-bf7e-3a4f1c2eb8a5",
   "metadata": {},
   "source": [
    "### 3.2 Baseline\n",
    "As an initial step for predicting hospitalization, we built basic models using Random Forest and LightGBM to establish baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcf28350-10e4-47db-9a36-f72bfe9a253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Random Forest Classification Model\n",
    "# ----------------------------\n",
    "\n",
    "# ----------------------------\n",
    "# Model training and prediction (Random Forest)\n",
    "# ----------------------------\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=200, max_depth=10)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf_base = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "901902d7-10d1-4057-b877-64b65ea451a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 9825, number of negative: 9946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 690\n",
      "[LightGBM] [Info] Number of data points in the train set: 19771, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496940 -> initscore=-0.012240\n",
      "[LightGBM] [Info] Start training from score -0.012240\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# LightGBM Classification Model\n",
    "# ----------------------------\n",
    "\n",
    "# ----------------------------\n",
    "# Re-splitting the data (just for clarity)\n",
    "# ----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_class, random_state=42)\n",
    "\n",
    "# ----------------------------\n",
    "# Model training and prediction (LightGBM)\n",
    "# ----------------------------\n",
    "model = LGBMClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_lgb_base = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933b432c-276c-4075-8d2b-1db5878aef8e",
   "metadata": {},
   "source": [
    "### 3.3 Baseline Comparison and Evaluation\n",
    "We compared the Random Forest and LightGBM classification models built as baselines using evaluation metrics such as accuracy, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11ddd0f3-c468-43ba-b641-75e53a66e180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.844485</td>\n",
       "      <td>0.848081</td>\n",
       "      <td>0.843704</td>\n",
       "      <td>0.852503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.849795</td>\n",
       "      <td>0.854283</td>\n",
       "      <td>0.844095</td>\n",
       "      <td>0.864720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Accuracy        F1  Precision    Recall\n",
       "0  RandomForest  0.844485  0.848081   0.843704  0.852503\n",
       "1      LightGBM  0.849795  0.854283   0.844095  0.864720"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================\n",
    "# Summary of Classification Model Evaluation\n",
    "# ============================\n",
    "\n",
    "# Collecting evaluation metrics (Accuracy, F1, Precision, Recall) for each model\n",
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"RandomForest\", \"LightGBM\"],\n",
    "    \"Accuracy\": [accuracy_score(y_test, y_pred_rf_base), accuracy_score(y_test, y_pred_lgb_base)],\n",
    "    \"F1\": [f1_score(y_test, y_pred_rf_base), f1_score(y_test, y_pred_lgb_base)],\n",
    "    \"Precision\": [precision_score(y_test, y_pred_rf_base), precision_score(y_test, y_pred_lgb_base)],\n",
    "    \"Recall\": [recall_score(y_test, y_pred_rf_base), recall_score(y_test, y_pred_lgb_base)],\n",
    "})\n",
    "\n",
    "# Displaying results\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14908e2-8e63-4e2a-8abb-6f8829386533",
   "metadata": {},
   "source": [
    "In this comparison, both Random Forest and LightGBM showed high classification performance. However, no significant difference was observed between the two models based on the evaluation metrics.\n",
    "Therefore, in the next section, we will explore the possibility of improving performance by optimizing hyperparameters for both models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1e9b8f-d331-4cbf-987b-200c7ff0d417",
   "metadata": {},
   "source": [
    "### 3.4 Model Hyperparameter Optimization\n",
    "To improve the performance of the baseline models, we optimized the hyperparameters of Random Forest and LightGBM using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea5d2165-1955-4ab9-b8c1-55ccfcfa000f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Random Forest Hyperparameter Optimization\n",
    "# ----------------------------\n",
    "\n",
    "# ----------------------------\n",
    "# Grid Search Parameter Settings\n",
    "# ----------------------------\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# Running Grid Search\n",
    "# ----------------------------\n",
    "grid_rf = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',  # Use F1 score as evaluation metric\n",
    "    cv=3,          # 3-fold cross-validation\n",
    "    verbose=1      # Enable log output\n",
    ")\n",
    "\n",
    "# Training the Model\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "# ----------------------------\n",
    "# Retraining with the Best Parameters\n",
    "# ----------------------------\n",
    "best_params = grid_rf.best_params_  # Retrieve optimal hyperparameters\n",
    "best_rf_model = RandomForestClassifier(**best_params, random_state=42)  # Apply best parameters\n",
    "best_rf_model.fit(X_train, y_train)  # Retrain model\n",
    "\n",
    "# ----------------------------\n",
    "# Making Predictions on Test Data\n",
    "# ----------------------------\n",
    "y_pred_rf_opt = best_rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac2abf8-65f8-4217-ada4-a715cf077903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# LightGBM Hyperparameter Optimization\n",
    "# ----------------------------\n",
    "\n",
    "# Setting Candidate Parameters (for hyperparameter tuning)\n",
    "params = {\n",
    "    'num_leaves': [31, 50],          # Number of leaves (affects model complexity)\n",
    "    'max_depth': [-1, 10, 20],       # Tree depth (-1 means no limit)\n",
    "    'learning_rate': [0.1, 0.05],    # Learning rate (smaller value = slower but more stable learning)\n",
    "    'n_estimators': [100, 200]       # Number of boosting iterations (trees)\n",
    "}\n",
    "\n",
    "# Creating a Model Instance (with default and fixed parameters)\n",
    "gbm = LGBMClassifier(random_state=42, verbose=-1)\n",
    "\n",
    "# Finding Optimal Parameters Using Grid Search (with cross-validation)\n",
    "grid = GridSearchCV(\n",
    "    estimator=gbm,          # Model\n",
    "    param_grid=params,      # Parameters to search\n",
    "    cv=3,                   # 3-fold cross-validation\n",
    "    scoring='f1',           # Optimization metric: F1 score\n",
    "    verbose=0               # Suppress log output (0 = silent)\n",
    ")\n",
    "\n",
    "# Running the Hyperparameter Search\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# ----------------------------\n",
    "# Retraining with the Best Parameters (LightGBM)\n",
    "# ----------------------------\n",
    "\n",
    "# Retrieve Best Model from Optimal Parameters\n",
    "best_lgb_model = grid.best_estimator_\n",
    "\n",
    "# Predicting on Test Data\n",
    "y_pred_lgb_opt = best_lgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce9d2dd-c02e-4e24-b549-d0faac2e4ba9",
   "metadata": {},
   "source": [
    "### 3.5 Comparison and Evaluation of Optimized Models\n",
    "The models after hyperparameter tuning were compared to assess differences in performance improvements and prediction capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df04a931-931e-4136-9d8e-f39c61b89ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Summary of Model Evaluation Results (Accuracy, F1, Precision, Recall)\n",
    "# ----------------------------\n",
    "results = pd.DataFrame({\n",
    "    \"Model\": [\n",
    "        \"RandomForest (Base)\",       # Baseline Random Forest\n",
    "        \"LightGBM (Base)\",           # Baseline LightGBM\n",
    "        \"RandomForest (Optimized)\",  # Random Forest after optimization\n",
    "        \"LightGBM (Optimized)\"       # LightGBM after optimization\n",
    "    ],\n",
    "    \"Accuracy\": [\n",
    "        accuracy_score(y_test, y_pred_rf_base),\n",
    "        accuracy_score(y_test, y_pred_lgb_base),\n",
    "        accuracy_score(y_test, y_pred_rf_opt),\n",
    "        accuracy_score(y_test, y_pred_lgb_opt)\n",
    "    ],\n",
    "    \"F1\": [\n",
    "        f1_score(y_test, y_pred_rf_base),\n",
    "        f1_score(y_test, y_pred_lgb_base),\n",
    "        f1_score(y_test, y_pred_rf_opt),\n",
    "        f1_score(y_test, y_pred_lgb_opt)\n",
    "    ],\n",
    "    \"Precision\": [\n",
    "        precision_score(y_test, y_pred_rf_base),\n",
    "        precision_score(y_test, y_pred_lgb_base),\n",
    "        precision_score(y_test, y_pred_rf_opt),\n",
    "        precision_score(y_test, y_pred_lgb_opt)\n",
    "    ],\n",
    "    \"Recall\": [\n",
    "        recall_score(y_test, y_pred_rf_base),\n",
    "        recall_score(y_test, y_pred_lgb_base),\n",
    "        recall_score(y_test, y_pred_rf_opt),\n",
    "        recall_score(y_test, y_pred_lgb_opt)\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Display of Results\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d90af7-d51d-4b09-bb07-c29d6c41f486",
   "metadata": {},
   "source": [
    "As a result of the optimization, LightGBM showed higher F1 score and recall by 0.01 to 0.03 points, and overall outperformed RandomForest.\n",
    "The F1 score is a particularly important evaluation metric and reflects the overall balance of the model, suggesting LightGBM's superiority.\n",
    "However, RandomForest also maintained competitive accuracy, which should be taken into consideration as a supporting factor in model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e673d693-a576-4f70-9fcb-0f3ed5909a2f",
   "metadata": {},
   "source": [
    "### 3.6 Feature Interpretation Using SHAP\n",
    "To enhance interpretability, SHAP values were used on the final LightGBM model to visualize which features had the greatest impact on predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dac2b5-9495-4389-a5f8-93cd9c56ef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# SHAP Value Visualization (LightGBM Model)\n",
    "# ----------------------------\n",
    "\n",
    "# Create explainer (explains the internal model)\n",
    "explainer = shap.Explainer(best_lgb_model)\n",
    "\n",
    "# Compute SHAP values (extract contributions for test data)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Summary plot (visualize average impact per feature)\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9704ffaa-a70c-4db5-8e91-bf1a1a1136c0",
   "metadata": {},
   "source": [
    "The feature that had the greatest impact on the model was ONSET_MONTH (month of onset); the higher the month value (e.g., December and other winter months), the greater the likelihood of hospitalization. The next most influential feature was ER_ED_VISIT (experience of receiving emergency treatment), which suggested that patients who visited the emergency department had a higher risk of hospitalization. Regarding AGE_YRS (age), it was observed that the likelihood of hospitalization tends to increase with age."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92452401-7097-46b2-9b60-aae70417780f",
   "metadata": {},
   "source": [
    "## 4.Conclusion and Business Implications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1162e416-8ecc-4903-a6fd-46047ecdd1e5",
   "metadata": {},
   "source": [
    "In this analysis, we aimed to quantitatively assess the risk of hospitalization after vaccination by constructing and comparing regression models to predict the number of hospitalization days, as well as classification models to predict the presence or absence of hospitalization.\n",
    "\n",
    "In the regression model, we optimized RandomForest and LightGBM, but both had R² values below 0.05, indicating insufficient precision for practical use. One likely reason is the absence of critical information such as medical history, pre-existing conditions, or social background, which strongly influence the number of hospitalization days.\n",
    "\n",
    "On the other hand, the classification models predicting whether a patient would be hospitalized achieved high performance, with an F1 score and recall of 0.83, demonstrating the potential for practical prediction. Feature importance analysis using SHAP revealed that ONSET_LAG (days until symptom onset), ER_ED_VISIT (emergency visit), and AGE_YRS (age) had particularly strong influences on the hospitalization decision.\n",
    "\n",
    "In terms of business applications, this model could be used as a decision-support tool in hospitals to help forecast and adjust bed utilization rates and to prepare staffing and resources (e.g., medication, food). Additionally, it could support decision-making regarding the necessity of hospitalization.\n",
    "\n",
    "Future analysis may improve the accuracy of hospitalization day predictions by incorporating factors such as patients’ medical histories, chronic conditions, caregiving situations, and living arrangements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c9aaf0-bccf-4d02-a41a-5c9607237301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fraud-detect)",
   "language": "python",
   "name": "fraud-detect"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
